{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –ü—Ä–æ–≤–µ—Ä–∫–∞ GPU\n",
    "\n",
    "!nvidia-smi\n",
    "\n",
    "import torch\n",
    "\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –ú–æ–Ω—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ Google Drive\n",
    "\n",
    "from google.colab import drive\n",
    "\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "!mkdir -p /content/drive/MyDrive/LSTM_Trading_Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –ö–ª–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ –∏ —É—Å—Ç–∞–Ω–æ–≤–∫–∞\n",
    "\n",
    "!git clone https://github.com/askimer/LSTM-Trading-Bot.git\n",
    "\n",
    "%cd LSTM-Trading-Bot\n",
    "\n",
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –ó–∞–ø—É—Å–∫ –ø–∞–π–ø–ª–∞–π–Ω–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥–∞–Ω–Ω—ã—Ö\n",
    "\n",
    "print(\"üöÄ –ó–∞–ø—É—Å–∫ –ø–∞–π–ø–ª–∞–π–Ω–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥–∞–Ω–Ω—ã—Ö...\")\n",
    "\n",
    "\n",
    "\n",
    "!python get_price_data.py\n",
    "\n",
    "print(\"‚úÖ –î–∞–Ω–Ω—ã–µ —Å–∫–∞—á–∞–Ω—ã\")\n",
    "\n",
    "\n",
    "\n",
    "!python clean_data.py\n",
    "\n",
    "print(\"‚úÖ –î–∞–Ω–Ω—ã–µ –æ—á–∏—â–µ–Ω—ã\")\n",
    "\n",
    "\n",
    "\n",
    "!python feature_engineer.py\n",
    "\n",
    "print(\"‚úÖ –ò–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã –¥–æ–±–∞–≤–ª–µ–Ω—ã\")\n",
    "\n",
    "\n",
    "\n",
    "print(\"üíæ –î–∞–Ω–Ω—ã–µ –≥–æ—Ç–æ–≤—ã –¥–ª—è –æ–±—É—á–µ–Ω–∏—è\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –ü–û–õ–ù–û–¶–ï–ù–ù–û–ï –û–ë–£–ß–ï–ù–ò–ï LSTM –° RandomizedSearchCV\n",
    "\n",
    "import torch\n",
    "\n",
    "import torch.nn as nn\n",
    "\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "from skorch import NeuralNetRegressor\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "from skorch.callbacks import EarlyStopping\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pickle\n",
    "\n",
    "import time\n",
    "\n",
    "import os\n",
    "\n",
    "\n",
    "\n",
    "class LSTMRegressor(nn.Module):\n",
    "\n",
    "    def __init__(self, input_dim, hidden_dim, num_layers=1):\n",
    "\n",
    "        super(LSTMRegressor, self).__init__()\n",
    "\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers=num_layers, batch_first=True)\n",
    "\n",
    "        self.linear = nn.Linear(hidden_dim, 1)\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        lstm_out, _ = self.lstm(x)\n",
    "\n",
    "        predictions = self.linear(lstm_out[:, -1])\n",
    "\n",
    "        return predictions\n",
    "\n",
    "\n",
    "\n",
    "def full_train_lstm():\n",
    "\n",
    "    print(\"üöÄ –ù–∞—á–∏–Ω–∞–µ–º –ü–û–õ–ù–û–¶–ï–ù–ù–û–ï –æ–±—É—á–µ–Ω–∏–µ LSTM —Å RandomizedSearchCV...\")\n",
    "\n",
    "    print(\"‚è±Ô∏è –û–∂–∏–¥–∞–µ–º–æ–µ –≤—Ä–µ–º—è: 2-4 —á–∞—Å–∞ –Ω–∞ GPU\")\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    \n",
    "\n",
    "    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è —Ñ–∞–π–ª–∞ –¥–∞–Ω–Ω—ã—Ö\n",
    "\n",
    "    data_file = 'btc_usdt_training_data/full_btc_usdt_data_feature_engineered.csv'\n",
    "\n",
    "    if not os.path.exists(data_file):\n",
    "\n",
    "        print(f\"‚ùå –§–∞–π–ª –¥–∞–Ω–Ω—ã—Ö –Ω–µ –Ω–∞–π–¥–µ–Ω: {data_file}\")\n",
    "\n",
    "        print(f\"–¢–µ–∫—É—â–∞—è –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è: {os.getcwd()}\")\n",
    "\n",
    "        print(\"–°–æ–¥–µ—Ä–∂–∏–º–æ–µ —Ç–µ–∫—É—â–µ–π –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏:\")\n",
    "\n",
    "        try:\n",
    "\n",
    "            print(os.listdir('.'))\n",
    "\n",
    "        except:\n",
    "\n",
    "            print(\"–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å —Å–ø–∏—Å–æ–∫ —Ñ–∞–π–ª–æ–≤\")\n",
    "\n",
    "        print(\"–ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ btc_usdt_training_data:\")\n",
    "\n",
    "        if os.path.exists('btc_usdt_training_data'):\n",
    "\n",
    "            print(\"–î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è —Å—É—â–µ—Å—Ç–≤—É–µ—Ç, —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ:\")\n",
    "\n",
    "            try:\n",
    "\n",
    "                print(os.listdir('btc_usdt_training_data'))\n",
    "\n",
    "            except:\n",
    "\n",
    "                print(\"–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å —Å–ø–∏—Å–æ–∫ —Ñ–∞–π–ª–æ–≤ –≤ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏\")\n",
    "\n",
    "        else:\n",
    "\n",
    "            print(\"–î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è btc_usdt_training_data –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç\")\n",
    "\n",
    "        raise FileNotFoundError(f\"–§–∞–π–ª –¥–∞–Ω–Ω—ã—Ö {data_file} –Ω–µ –Ω–∞–π–¥–µ–Ω. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –ø—Ä–µ–¥—ã–¥—É—â–∏—Ö —à–∞–≥–æ–≤ –ø–∞–π–ø–ª–∞–π–Ω–∞.\")\n",
    "\n",
    "    \n",
    "\n",
    "    # –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö\n",
    "\n",
    "    df = pd.read_csv(data_file)\n",
    "\n",
    "    df = df.dropna()\n",
    "\n",
    "    \n",
    "\n",
    "    # –£–¥–∞–ª–µ–Ω–∏–µ –∫–æ–Ω—Å—Ç–∞–Ω—Ç–Ω—ã—Ö —Å—Ç–æ–ª–±—Ü–æ–≤\n",
    "\n",
    "    std_dev = df.std()\n",
    "\n",
    "    non_constant_columns = std_dev[std_dev != 0].index.tolist()\n",
    "\n",
    "    df = df[non_constant_columns]\n",
    "\n",
    "    \n",
    "\n",
    "    X = df.drop('close', axis=1).values\n",
    "\n",
    "    y = df['close'].values.reshape(-1, 1)\n",
    "\n",
    "    \n",
    "\n",
    "    # –ú–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ\n",
    "\n",
    "    scaler_X = StandardScaler()\n",
    "\n",
    "    X = scaler_X.fit_transform(X)\n",
    "\n",
    "    \n",
    "\n",
    "    scaler_y = StandardScaler()\n",
    "\n",
    "    y = scaler_y.fit_transform(y)\n",
    "\n",
    "    \n",
    "\n",
    "    # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Å–∫–µ–π–ª–µ—Ä–æ–≤\n",
    "\n",
    "    with open('scaler_X.pkl', 'wb') as f:\n",
    "\n",
    "        pickle.dump(scaler_X, f)\n",
    "\n",
    "    with open('scaler_y.pkl', 'wb') as f:\n",
    "\n",
    "        pickle.dump(scaler_y, f)\n",
    "\n",
    "    \n",
    "\n",
    "    # –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    \n",
    "\n",
    "    # –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –≤ —Ç–µ–Ω–∑–æ—Ä—ã\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    print(f\"üìä –û–±—É—á–µ–Ω–∏–µ –Ω–∞ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–µ: {device}\")\n",
    "\n",
    "    \n",
    "\n",
    "    n_features = X_train.shape[1]\n",
    "\n",
    "    X_train_tensor = torch.tensor(np.array(X_train, copy=True, order='C').reshape(-1, 1, n_features), dtype=torch.float32).to(device)\n",
    "\n",
    "    y_train_tensor = torch.tensor(np.array(y_train, copy=True, order='C'), dtype=torch.float32).to(device)\n",
    "\n",
    "    X_test_tensor = torch.tensor(np.array(X_test, copy=True, order='C').reshape(-1, 1, n_features), dtype=torch.float32).to(device)\n",
    "\n",
    "    y_test_tensor = torch.tensor(np.array(y_test, copy=True, order='C'), dtype=torch.float32).to(device)\n",
    "\n",
    "    \n",
    "\n",
    "    # –°–æ–∑–¥–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏ –¥–ª—è –ø–æ–∏—Å–∫–∞\n",
    "\n",
    "    net = NeuralNetRegressor(\n",
    "\n",
    "        LSTMRegressor,\n",
    "\n",
    "        module__input_dim=n_features,\n",
    "\n",
    "        max_epochs=50,\n",
    "\n",
    "        iterator_train__shuffle=True,\n",
    "\n",
    "        device=device,\n",
    "\n",
    "        callbacks=[EarlyStopping(patience=5)],\n",
    "\n",
    "        verbose=0\n",
    "\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "    # –ü–æ–ª–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è –ø–æ–∏—Å–∫–∞\n",
    "\n",
    "    params = {\n",
    "\n",
    "        'module__hidden_dim': [128, 256, 384, 512, 768, 1024],\n",
    "\n",
    "        'module__num_layers': [2, 3, 4, 5, 6],\n",
    "\n",
    "        'lr': [0.02, 0.015, 0.01, 0.005, 0.001],\n",
    "\n",
    "        'batch_size': [64, 128, 192, 256, 384, 512],\n",
    "\n",
    "        'max_epochs': [20, 30, 40, 50]\n",
    "\n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "    total_combinations = (len(params['module__hidden_dim']) * len(params['module__num_layers']) * \n",
    "\n",
    "                          len(params['lr']) * len(params['batch_size']) * len(params['max_epochs']))\n",
    "\n",
    "    print(f\"üéØ –ü–æ–ª–Ω—ã–π –ø–æ–∏—Å–∫: {total_combinations} –≤–æ–∑–º–æ–∂–Ω—ã—Ö –∫–æ–º–±–∏–Ω–∞—Ü–∏–π\")\n",
    "\n",
    "    print(\"üîç RandomizedSearchCV: 20 —Å–ª—É—á–∞–π–Ω—ã—Ö –∫–æ–º–±–∏–Ω–∞—Ü–∏–π √ó 3-fold CV = 60 –æ–±—É—á–µ–Ω–∏–π\")\n",
    "\n",
    "    \n",
    "\n",
    "    # RandomizedSearchCV\n",
    "\n",
    "    random_search = RandomizedSearchCV(\n",
    "\n",
    "        net,\n",
    "\n",
    "        params,\n",
    "\n",
    "        n_iter=20,  # 20 —Å–ª—É—á–∞–π–Ω—ã—Ö –∫–æ–º–±–∏–Ω–∞—Ü–∏–π\n",
    "\n",
    "        cv=3,\n",
    "\n",
    "        scoring='neg_mean_squared_error',\n",
    "\n",
    "        n_jobs=1,  # –ü–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ –¥–ª—è —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏\n",
    "\n",
    "        random_state=42,\n",
    "\n",
    "        verbose=2\n",
    "\n",
    "    )\n",
    "\n",
    "    \n",
    "\n",
    "    print(\"\\nüèÉ –ù–∞—á–∏–Ω–∞–µ–º –æ–±—É—á–µ–Ω–∏–µ...\")\n",
    "\n",
    "    random_search.fit(X_train_tensor, y_train_tensor)\n",
    "\n",
    "    \n",
    "\n",
    "    # –†–µ–∑—É–ª—å—Ç–∞—Ç—ã\n",
    "\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "\n",
    "    print(\"üèÜ –†–ï–ó–£–õ–¨–¢–ê–¢–´ –ü–û–ò–°–ö–ê\")\n",
    "\n",
    "    print(\"=\"*60)\n",
    "\n",
    "    \n",
    "\n",
    "    best_params = random_search.best_params_\n",
    "\n",
    "    print(\"–õ—É—á—à–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã:\")\n",
    "\n",
    "    for param, value in best_params.items():\n",
    "\n",
    "        print(f\"  {param}: {value}\")\n",
    "\n",
    "    \n",
    "\n",
    "    best_score = -random_search.best_score_  # neg_mean_squared_error -> positive\n",
    "\n",
    "    print(f\"\\n–õ—É—á—à–∏–π MSE: {best_score:.6f}\")\n",
    "\n",
    "    \n",
    "\n",
    "    # –§–∏–Ω–∞–ª—å–Ω–∞—è –æ—Ü–µ–Ω–∫–∞ –ª—É—á—à–µ–π –º–æ–¥–µ–ª–∏\n",
    "\n",
    "    best_model = random_search.best_estimator_\n",
    "\n",
    "    y_pred = best_model.predict(X_test_tensor)\n",
    "\n",
    "    final_mse = mean_squared_error(y_test_tensor.cpu(), y_pred.cpu())\n",
    "\n",
    "    print(f\"MSE –Ω–∞ —Ç–µ—Å—Ç–µ: {final_mse:.6f}\")\n",
    "\n",
    "    \n",
    "\n",
    "    training_time = time.time() - start_time\n",
    "\n",
    "    print(f\"\\n‚è±Ô∏è –û–±—â–µ–µ –≤—Ä–µ–º—è –æ–±—É—á–µ–Ω–∏—è: {training_time/3600:.1f} —á–∞—Å–æ–≤\")\n",
    "\n",
    "    \n",
    "\n",
    "    # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –ª—É—á—à–µ–π –º–æ–¥–µ–ª–∏\n",
    "\n",
    "    torch.save(best_model, 'best_lstm_model_full.pt')\n",
    "\n",
    "    \n",
    "\n",
    "    # –ö–æ–ø–∏—Ä–æ–≤–∞–Ω–∏–µ –Ω–∞ Google Drive\n",
    "\n",
    "    !cp best_lstm_model_full.pt /content/drive/MyDrive/LSTM_Trading_Models/\n",
    "\n",
    "    !cp scaler_X.pkl /content/drive/MyDrive/LSTM_Trading_Models/\n",
    "\n",
    "    !cp scaler_y.pkl /content/drive/MyDrive/LSTM_Trading_Models/\n",
    "\n",
    "    \n",
    "\n",
    "    print(\"\\nüíæ –õ—É—á—à–∞—è –º–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –Ω–∞ Google Drive\")\n",
    "\n",
    "    \n",
    "\n",
    "    # –ì—Ä–∞—Ñ–∏–∫ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –ø–æ–∏—Å–∫–∞\n",
    "\n",
    "    cv_results = pd.DataFrame(random_search.cv_results_)\n",
    "\n",
    "    plt.figure(figsize=(12, 8))\n",
    "\n",
    "    \n",
    "\n",
    "    # –¢–æ–ø-10 —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤\n",
    "\n",
    "    top_10 = cv_results.nlargest(10, 'mean_test_score')\n",
    "\n",
    "    plt.bar(range(len(top_10)), -top_10['mean_test_score'], alpha=0.7)\n",
    "\n",
    "    plt.title('–¢–æ–ø-10 –∫–æ–º–±–∏–Ω–∞—Ü–∏–π –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ (MSE)')\n",
    "\n",
    "    plt.xlabel('–ö–æ–º–±–∏–Ω–∞—Ü–∏—è')\n",
    "\n",
    "    plt.ylabel('MSE')\n",
    "\n",
    "    plt.grid(True)\n",
    "\n",
    "    plt.savefig('hyperparameter_search_results.png', dpi=150, bbox_inches='tight')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "\n",
    "    !cp hyperparameter_search_results.png /content/drive/MyDrive/LSTM_Trading_Models/\n",
    "\n",
    "    \n",
    "\n",
    "    return best_model, final_mse\n",
    "\n",
    "\n",
    "\n",
    "# –ó–∞–ø—É—Å–∫ –ø–æ–ª–Ω–æ—Ü–µ–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è\n",
    "\n",
    "best_model, final_mse = full_train_lstm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –§–∏–Ω–∞–ª–∏–∑–∞—Ü–∏—è\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "\n",
    "print(\"üéâ –ü–û–õ–ù–û–¶–ï–ù–ù–û–ï –û–ë–£–ß–ï–ù–ò–ï –ó–ê–í–ï–†–®–ï–ù–û!\")\n",
    "\n",
    "print(\"=\"*60)\n",
    "\n",
    "\n",
    "\n",
    "print(\"\\nüìÅ –°–û–•–†–ê–ù–ï–ù–ù–´–ï –§–ê–ô–õ–´:\")\n",
    "\n",
    "print(\"Google Drive: /MyDrive/LSTM_Trading_Models/\")\n",
    "\n",
    "print(\"- best_lstm_model_full.pt (–ª—É—á—à–∞—è –º–æ–¥–µ–ª—å)\")\n",
    "\n",
    "print(\"- scaler_X.pkl, scaler_y.pkl\")\n",
    "\n",
    "print(\"- hyperparameter_search_results.png\")\n",
    "\n",
    "\n",
    "\n",
    "print(\"\\nüí° –î–ê–õ–¨–ù–ï–ô–®–ò–ï –®–ê–ì–ò:\")\n",
    "\n",
    "print(\"1. –°–∫–∞—á–∞–π—Ç–µ –º–æ–¥–µ–ª—å —Å Google Drive\")\n",
    "\n",
    "print(\"2. –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –ª–æ–∫–∞–ª—å–Ω–æ —Å live_trading.py\")\n",
    "\n",
    "print(\"3. –î–ª—è RL –æ–±—É—á–µ–Ω–∏—è –∑–∞–ø—É—Å—Ç–∏—Ç–µ —Å–ª–µ–¥—É—é—â–∏–π notebook\")\n",
    "\n",
    "\n",
    "\n",
    "print(\"\\nüöÄ –ì–û–¢–û–í–û –ö –†–ï–ê–õ–¨–ù–û–ô –¢–û–†–ì–û–í–õ–ï!\")\n",
    "\n",
    "print(\"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
