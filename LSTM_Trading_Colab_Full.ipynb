{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üöÄ LSTM Algorithmic Trading Bot - Google Colab (–ü–æ–ª–Ω–∞—è –≤–µ—Ä—Å–∏—è)\n",
    "\n",
    "**–ü–æ–ª–Ω–æ—Ü–µ–Ω–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ —Å RandomizedSearchCV –Ω–∞ GPU**\n",
    "\n",
    "–≠—Ç–æ—Ç notebook –≤—ã–ø–æ–ª–Ω—è–µ—Ç –ø–æ–ª–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ LSTM –º–æ–¥–µ–ª–∏ —Å –ø–æ–∏—Å–∫–æ–º –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã—Ö –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤.\n",
    "\n",
    "## ‚ö° –û—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏:\n",
    "- ‚úÖ –ü–æ–ª–Ω–æ—Ü–µ–Ω–Ω—ã–π RandomizedSearchCV (20 –∫–æ–º–±–∏–Ω–∞—Ü–∏–π √ó 3-fold CV)\n",
    "- ‚úÖ –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –≤—ã–±–æ—Ä –ª—É—á—à–∏—Ö –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤\n",
    "- ‚úÖ GPU —É—Å–∫–æ—Ä–µ–Ω–∏–µ (Tesla T4/K80)\n",
    "- ‚úÖ –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –Ω–∞ Google Drive\n",
    "- ‚úÖ –û–∂–∏–¥–∞–µ–º–æ–µ –≤—Ä–µ–º—è: 2-4 —á–∞—Å–∞\n",
    "\n",
    "## ‚ö†Ô∏è –í–∞–∂–Ω–æ:\n",
    "- –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ –≤–∫–ª—é—á–µ–Ω GPU runtime\n",
    "- –ú–æ–Ω–∏—Ç–æ—Ä—å—Ç–µ –≤—Ä–µ–º—è (–Ω–µ –±–æ–ª–µ–µ 12 —á–∞—Å–æ–≤)\n",
    "- –ú–æ–¥–µ–ª–∏ —Å–æ—Ö—Ä–∞–Ω—è—é—Ç—Å—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –ü—Ä–æ–≤–µ—Ä–∫–∞ GPU\n",
    "!nvidia-smi\n",
    "import torch\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –ú–æ–Ω—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ Google Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "!mkdir -p /content/drive/MyDrive/LSTM_Trading_Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –ö–ª–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ –∏ —É—Å—Ç–∞–Ω–æ–≤–∫–∞\n",
    "# –ó–ê–ú–ï–ù–ò–¢–ï YOUR_GITHUB_TOKEN –Ω–∞ –≤–∞—à —Ç–æ–∫–µ–Ω –¥–æ—Å—Ç—É–ø–∞\n",
    "# –ü–æ–ª—É—á–∏—Ç—å —Ç–æ–∫–µ–Ω: https://github.com/settings/tokens\n",
    "!git clone https://oauth2:YOUR_GITHUB_TOKEN@github.com/askimer/LSTM-Trading-Bot.git\n",
    "%cd LSTM-Trading-Bot\n",
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –°–æ–∑–¥–∞–Ω–∏–µ –¥–µ–º–æ-–¥–∞–Ω–Ω—ã—Ö (–∏–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ —Å–≤–æ–∏)\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def create_demo_data():\n",
    "    np.random.seed(42)\n",
    "    dates = pd.date_range(start='2023-01-01', periods=10000, freq='1min')  # –ë–æ–ª—å—à–µ –¥–∞–Ω–Ω—ã—Ö\n",
    "    \n",
    "    base_price = 30000\n",
    "    trend = np.linspace(0, 15000, 10000)\n",
    "    noise = np.random.normal(0, 800, 10000)\n",
    "    \n",
    "    close_prices = base_price + trend + noise\n",
    "    close_prices = np.maximum(close_prices, 1000)\n",
    "    \n",
    "    high_prices = close_prices * (1 + np.abs(np.random.normal(0, 0.03, 10000)))\n",
    "    low_prices = close_prices * (1 - np.abs(np.random.normal(0, 0.03, 10000)))\n",
    "    open_prices = np.roll(close_prices, 1)\n",
    "    open_prices[0] = close_prices[0]\n",
    "    \n",
    "    volume = np.random.uniform(50, 2000, 10000)\n",
    "    \n",
    "    df = pd.DataFrame({\n",
    "        'timestamp': dates,\n",
    "        'open': open_prices,\n",
    "        'high': high_prices,\n",
    "        'low': low_prices,\n",
    "        'close': close_prices,\n",
    "        'volume': volume\n",
    "    })\n",
    "    \n",
    "    return df\n",
    "\n",
    "# –°–æ–∑–¥–∞–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö\n",
    "demo_df = create_demo_data()\n",
    "print(f\"‚úÖ –°–æ–∑–¥–∞–Ω–æ {len(demo_df)} —Å—Ç—Ä–æ–∫ –¥–∞–Ω–Ω—ã—Ö\")\n",
    "\n",
    "!mkdir -p btc_usdt_training_data\n",
    "demo_df.to_csv('btc_usdt_training_data/full_btc_usdt_data_feature_engineered.csv', index=False)\n",
    "print(\"üíæ –î–∞–Ω–Ω—ã–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –ü–û–õ–ù–û–¶–ï–ù–ù–û–ï –û–ë–£–ß–ï–ù–ò–ï LSTM –° RandomizedSearchCV\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from skorch import NeuralNetRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from skorch.callbacks import EarlyStopping\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import time\n",
    "\n",
    "class LSTMRegressor(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, num_layers=1):\n",
    "        super(LSTMRegressor, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers=num_layers, batch_first=True)\n",
    "        self.linear = nn.Linear(hidden_dim, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        lstm_out, _ = self.lstm(x)\n",
    "        predictions = self.linear(lstm_out[:, -1])\n",
    "        return predictions\n",
    "\n",
    "def full_train_lstm():\n",
    "    print(\"üöÄ –ù–∞—á–∏–Ω–∞–µ–º –ü–û–õ–ù–û–¶–ï–ù–ù–û–ï –æ–±—É—á–µ–Ω–∏–µ LSTM —Å RandomizedSearchCV...\")\n",
    "    print(\"‚è±Ô∏è –û–∂–∏–¥–∞–µ–º–æ–µ –≤—Ä–µ–º—è: 2-4 —á–∞—Å–∞ –Ω–∞ GPU\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö\n",
    "    df = pd.read_csv('btc_usdt_training_data/full_btc_usdt_data_feature_engineered.csv')\n",
    "    df = df.dropna()\n",
    "    \n",
    "    # –£–¥–∞–ª–µ–Ω–∏–µ –∫–æ–Ω—Å—Ç–∞–Ω—Ç–Ω—ã—Ö —Å—Ç–æ–ª–±—Ü–æ–≤\n",
    "    std_dev = df.std()\n",
    "    non_constant_columns = std_dev[std_dev != 0].index.tolist()\n",
    "    df = df[non_constant_columns]\n",
    "    \n",
    "    X = df.drop('close', axis=1).values\n",
    "    y = df['close'].values.reshape(-1, 1)\n",
    "    \n",
    "    # –ú–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ\n",
    "    scaler_X = StandardScaler()\n",
    "    X = scaler_X.fit_transform(X)\n",
    "    \n",
    "    scaler_y = StandardScaler()\n",
    "    y = scaler_y.fit_transform(y)\n",
    "    \n",
    "    # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Å–∫–µ–π–ª–µ—Ä–æ–≤\n",
    "    with open('scaler_X.pkl', 'wb') as f:\n",
    "        pickle.dump(scaler_X, f)\n",
    "    with open('scaler_y.pkl', 'wb') as f:\n",
    "        pickle.dump(scaler_y, f)\n",
    "    \n",
    "    # –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –≤ —Ç–µ–Ω–∑–æ—Ä—ã\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"üìä –û–±—É—á–µ–Ω–∏–µ –Ω–∞ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–µ: {device}\")\n",
    "    \n",
    "    n_features = X_train.shape[1]\n",
    "    X_train_tensor = torch.tensor(np.array(X_train, copy=True, order='C').reshape(-1, 1, n_features), dtype=torch.float32).to(device)\n",
    "    y_train_tensor = torch.tensor(np.array(y_train, copy=True, order='C'), dtype=torch.float32).to(device)\n",
    "    X_test_tensor = torch.tensor(np.array(X_test, copy=True, order='C').reshape(-1, 1, n_features), dtype=torch.float32).to(device)\n",
    "    y_test_tensor = torch.tensor(np.array(y_test, copy=True, order='C'), dtype=torch.float32).to(device)\n",
    "    \n",
    "    # –°–æ–∑–¥–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏ –¥–ª—è –ø–æ–∏—Å–∫–∞\n",
    "    net = NeuralNetRegressor(\n",
    "        LSTMRegressor,\n",
    "        module__input_dim=n_features,\n",
    "        max_epochs=50,\n",
    "        iterator_train__shuffle=True,\n",
    "        device=device,\n",
    "        callbacks=[EarlyStopping(patience=5)],\n",
    "        verbose=0\n",
    "    )\n",
    "\n",
    "    # –ü–æ–ª–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è –ø–æ–∏—Å–∫–∞\n",
    "    params = {\n",
    "        'module__hidden_dim': [128, 256, 384, 512, 768, 1024],\n",
    "        'module__num_layers': [2, 3, 4, 5, 6],\n",
    "        'lr': [0.02, 0.015, 0.01, 0.005, 0.001],\n",
    "        'batch_size': [64, 128, 192, 256, 384, 512],\n",
    "        'max_epochs': [20, 30, 40, 50]\n",
    "    }\n",
    "\n",
    "    total_combinations = (len(params['module__hidden_dim']) * len(params['module__num_layers']) * \n",
    "                          len(params['lr']) * len(params['batch_size']) * len(params['max_epochs']))\n",
    "    print(f\"üéØ –ü–æ–ª–Ω—ã–π –ø–æ–∏—Å–∫: {total_combinations} –≤–æ–∑–º–æ–∂–Ω—ã—Ö –∫–æ–º–±–∏–Ω–∞—Ü–∏–π\")\n",
    "    print(\"üîç RandomizedSearchCV: 20 —Å–ª—É—á–∞–π–Ω—ã—Ö –∫–æ–º–±–∏–Ω–∞—Ü–∏–π √ó 3-fold CV = 60 –æ–±—É—á–µ–Ω–∏–π\")\n",
    "    \n",
    "    # RandomizedSearchCV\n",
    "    random_search = RandomizedSearchCV(\n",
    "        net,\n",
    "        params,\n",
    "        n_iter=20,  # 20 —Å–ª—É—á–∞–π–Ω—ã—Ö –∫–æ–º–±–∏–Ω–∞—Ü–∏–π\n",
    "        cv=3,\n",
    "        scoring='neg_mean_squared_error',\n",
    "        n_jobs=1,  # –ü–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ –¥–ª—è —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏\n",
    "        random_state=42,\n",
    "        verbose=2\n",
    "    )\n",
    "    \n",
    "    print(\"\\nüèÉ –ù–∞—á–∏–Ω–∞–µ–º –æ–±—É—á–µ–Ω–∏–µ...\")\n",
    "    random_search.fit(X_train_tensor, y_train_tensor)\n",
    "    \n",
    "    # –†–µ–∑—É–ª—å—Ç–∞—Ç—ã\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"üèÜ –†–ï–ó–£–õ–¨–¢–ê–¢–´ –ü–û–ò–°–ö–ê\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    best_params = random_search.best_params_\n",
    "    print(\"–õ—É—á—à–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã:\")\n",
    "    for param, value in best_params.items():\n",
    "        print(f\"  {param}: {value}\")\n",
    "    \n",
    "    best_score = -random_search.best_score_  # neg_mean_squared_error -> positive\n",
    "    print(f\"\\n–õ—É—á—à–∏–π MSE: {best_score:.6f}\")\n",
    "    \n",
    "    # –§–∏–Ω–∞–ª—å–Ω–∞—è –æ—Ü–µ–Ω–∫–∞ –ª—É—á—à–µ–π –º–æ–¥–µ–ª–∏\n",
    "    best_model = random_search.best_estimator_\n",
    "    y_pred = best_model.predict(X_test_tensor)\n",
    "    final_mse = mean_squared_error(y_test_tensor.cpu(), y_pred.cpu())\n",
    "    print(f\"MSE –Ω–∞ —Ç–µ—Å—Ç–µ: {final_mse:.6f}\")\n",
    "    \n",
    "    training_time = time.time() - start_time\n",
    "    print(f\"\\n‚è±Ô∏è –û–±—â–µ–µ –≤—Ä–µ–º—è –æ–±—É—á–µ–Ω–∏—è: {training_time/3600:.1f} —á–∞—Å–æ–≤\")\n",
    "    \n",
    "    # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –ª—É—á—à–µ–π –º–æ–¥–µ–ª–∏\n",
    "    torch.save(best_model, 'best_lstm_model_full.pt')\n",
    "    \n",
    "    # –ö–æ–ø–∏—Ä–æ–≤–∞–Ω–∏–µ –Ω–∞ Google Drive\n",
    "    !cp best_lstm_model_full.pt /content/drive/MyDrive/LSTM_Trading_Models/\n",
    "    !cp scaler_X.pkl /content/drive/MyDrive/LSTM_Trading_Models/\n",
    "    !cp scaler_y.pkl /content/drive/MyDrive/LSTM_Trading_Models/\n",
    "    \n",
    "    print(\"\\nüíæ –õ—É—á—à–∞—è –º–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –Ω–∞ Google Drive\")\n",
    "    \n",
    "    # –ì—Ä–∞—Ñ–∏–∫ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –ø–æ–∏—Å–∫–∞\n",
    "    cv_results = pd.DataFrame(random_search.cv_results_)\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    \n",
    "    # –¢–æ–ø-10 —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤\n",
    "    top_10 = cv_results.nlargest(10, 'mean_test_score')\n",
    "    plt.bar(range(len(top_10)), -top_10['mean_test_score'], alpha=0.7)\n",
    "    plt.title('–¢–æ–ø-10 –∫–æ–º–±–∏–Ω–∞—Ü–∏–π –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ (MSE)')\n",
    "    plt.xlabel('–ö–æ–º–±–∏–Ω–∞—Ü–∏—è')\n",
    "    plt.ylabel('MSE')\n",
    "    plt.grid(True)\n",
    "    plt.savefig('hyperparameter_search_results.png', dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    !cp hyperparameter_search_results.png /content/drive/MyDrive/LSTM_Trading_Models/\n",
    "    \n",
    "    return best_model, final_mse\n",
    "\n",
    "# –ó–∞–ø—É—Å–∫ –ø–æ–ª–Ω–æ—Ü–µ–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è\n",
    "best_model, final_mse = full_train_lstm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –§–∏–Ω–∞–ª–∏–∑–∞—Ü–∏—è\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üéâ –ü–û–õ–ù–û–¶–ï–ù–ù–û–ï –û–ë–£–ß–ï–ù–ò–ï –ó–ê–í–ï–†–®–ï–ù–û!\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\\nüìÅ –°–û–•–†–ê–ù–ï–ù–ù–´–ï –§–ê–ô–õ–´:\")\n",
    "print(\"Google Drive: /MyDrive/LSTM_Trading_Models/\")\n",
    "print(\"- best_lstm_model_full.pt (–ª—É—á—à–∞—è –º–æ–¥–µ–ª—å)\")\n",
    "print(\"- scaler_X.pkl, scaler_y.pkl\")\n",
    "print(\"- hyperparameter_search_results.png\")\n",
    "\n",
    "print(\"\\nüí° –î–ê–õ–¨–ù–ï–ô–®–ò–ï –®–ê–ì–ò:\")\n",
    "print(\"1. –°–∫–∞—á–∞–π—Ç–µ –º–æ–¥–µ–ª—å —Å Google Drive\")\n",
    "print(\"2. –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –ª–æ–∫–∞–ª—å–Ω–æ —Å live_trading.py\")\n",
    "print(\"3. –î–ª—è RL –æ–±—É—á–µ–Ω–∏—è –∑–∞–ø—É—Å—Ç–∏—Ç–µ —Å–ª–µ–¥—É—é—â–∏–π notebook\")\n",
    "\n",
    "print(\"\\nüöÄ –ì–û–¢–û–í–û –ö –†–ï–ê–õ–¨–ù–û–ô –¢–û–†–ì–û–í–õ–ï!\")\n",
    "print(\"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
