# ğŸš€ V19 Quick Start Guide

## âš¡ One-Command Training

```bash
python train_v19_dqn.py
```

That's it! Training will run for ~4-6 hours and save checkpoints to `./rl_checkpoints_v19_dqn_fixed/`

---

## ğŸ“‹ Prerequisites Check

```bash
# 1. Verify data file exists
ls -lh ./btc_usdt_training_data/full_btc_usdt_data_feature_engineered.csv

# 2. Verify dependencies
python -c "import stable_baselines3; import pandas; import numpy; import gymnasium; print('âœ… All dependencies OK')"

# 3. Verify V19 files exist
ls -lh train_v19_dqn.py eval_v19.py enhanced_trading_environment_v19.py
```

---

## ğŸ¯ Training Workflow

### Step 1: Start Training
```bash
python train_v19_dqn.py
```

**What you'll see:**
```
======================================================================
ğŸš€ DQN TRADING MODEL TRAINING v19 - CRITICAL FIXES APPLIED
======================================================================
Total timesteps: 1,000,000
Checkpoints: every 100,000 steps

V19 CRITICAL FIXES:
  P0 âœ… SaveBestCallback.best_model_path attribute added
  P0 âœ… Reward clipping: 50.0 â†’ 200.0 (prevents information loss)
  ...

Creating environments...
Creating DQN model...
  buffer_size: 100000
  exploration: 1.0 â†’ 0.05 (reduced for stability)
  ...

ğŸ“š STARTING DQN TRAINING v19...
----------------------------------------------------------------------

ğŸ’¾ Saving BEST model (reward=15.2341)...
âœ… Best model saved!
ğŸ’¾ Checkpoint: 100,000 steps
```

### Step 2: Monitor Training (Optional)

**Option A: TensorBoard**
```bash
tensorboard --logdir ./logs_v19/
# Open browser: http://localhost:6006
```

**Option B: Watch console output**
- Look for increasing `reward` values
- Checkpoints saved every 100K steps

### Step 3: Evaluate Model

After training completes:
```bash
python eval_v19.py
```

**Expected output:**
```
======================================================================
ğŸ“Š V19 DQN MODEL EVALUATION - CRITICAL FIXES
======================================================================

Ep1: return=+0.45%  trades=42 (L:23 S:19)  win=36%
Ep2: return=+0.12%  trades=48 (L:26 S:22)  win=33%
Ep3: return=+0.67%  trades=39 (L:21 S:18)  win=38%
Ep4: return=+0.28%  trades=45 (L:24 S:21)  win=35%

============================================================
SUMMARY
============================================================

ğŸ“Š PERFORMANCE METRICS:
â”œâ”€ Average Return:     +0.38%
â”œâ”€ Average Win Rate:   35.5%
â”œâ”€ Total Trades:       174 (43.5 per episode)
â”‚  â”œâ”€ Long:            94 (54%)
â”‚  â””â”€ Short:           80 (46%)
â””â”€ Win Rate (overall): 35.5%

ğŸ¯ V19 TARGETS:
â”œâ”€ Return > -0.3%:     âœ… PASS
â”œâ”€ Win Rate > 30%:     âœ… PASS
â”œâ”€ Trades < 60:        âœ… PASS
â””â”€ Short % > 20%:      âœ… PASS

âœ… ALL V19 TARGETS ACHIEVED!
```

---

## ğŸ”§ Common Issues

### Issue 1: "ModuleNotFoundError: No module named 'stable_baselines3'"

**Solution:**
```bash
pip install stable-baselines3
```

---

### Issue 2: "FileNotFoundError: [Errno 2] No such file or directory: '...feature_engineered.csv'"

**Solution:**
```bash
# Run feature engineering first
python feature_engineer.py
```

---

### Issue 3: Training is slow (< 100 steps/sec)

**Solutions:**
1. Reduce `N_ENVS` from 4 to 2 in `train_v19_dqn.py`
2. Use SSD storage for data files
3. Close other CPU-intensive applications

---

### Issue 4: GPU out of memory

**Solution:** V19 uses CPU-only by default. If using GPU:
```python
# Add to train_v19_dqn.py after DQN creation
model = DQN(..., device='cpu')  # Force CPU
```

---

## ğŸ“Š Expected Training Timeline

| Timesteps | Time Elapsed | Expected Mean Reward |
|-----------|--------------|---------------------|
| 0 | 0 min | 0 (random actions) |
| 100K | ~40 min | 5-10 (learning starts) |
| 200K | ~80 min | 10-15 (improving) |
| 500K | ~200 min | 15-20 (stable) |
| 1M | ~400 min | 20-25 (converged) |

---

## ğŸ¯ Success Metrics

After training, your model should achieve:

| Metric | Target | How to Check |
|--------|--------|--------------|
| Best Reward | > 15 | Console output during training |
| Return/Episode | > -0.3% | `eval_v19.py` |
| Win Rate | > 30% | `eval_v19.py` |
| Trades/Episode | < 60 | `eval_v19.py` |
| Short % | > 30% | `eval_v19.py` |

---

## ğŸ“ Output Files

After successful training:

```
./rl_checkpoints_v19_dqn_fixed/
â”œâ”€â”€ dqn_v19_100000_steps.zip      # Checkpoint at 100K steps
â”œâ”€â”€ dqn_v19_200000_steps.zip      # Checkpoint at 200K steps
â”œâ”€â”€ ...
â”œâ”€â”€ dqn_v19_1000000_steps.zip     # Final checkpoint
â””â”€â”€ dqn_v19_best.zip              # Best model (highest reward)

./logs_v19/
â””â”€â”€ dqn_v19_fixed/
    â””â”€â”€ events.out.tfevents.*     # TensorBoard logs
```

---

## ğŸš€ Next Steps

### After Successful Training:

1. **Evaluate:** `python eval_v19.py`
2. **Paper Trade:** Update model path in `paper_trade_hybrid.py`
3. **Deploy:** Use in live trading (with caution!)

### If Results Don't Meet Targets:

1. Check `V19_TRAINING_STATUS.md` for troubleshooting
2. Review TensorBoard logs
3. Adjust reward parameters in `enhanced_trading_environment_v19.py`

---

## ğŸ“ Quick Reference

| Command | Purpose |
|---------|---------|
| `python train_v19_dqn.py` | Start training |
| `python eval_v19.py` | Evaluate model |
| `tensorboard --logdir ./logs_v19/` | Monitor training |
| `cat V19_SUMMARY.md` | Full documentation |
| `cat V19_TRAINING_STATUS.md` | Detailed fixes |

---

**Last Updated:** 2026-02-27  
**Version:** V19  
**Status:** Production Ready âœ…
